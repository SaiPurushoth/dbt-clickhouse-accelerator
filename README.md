# ğŸš€ Open Source Analytics Accelerator:

# ğŸ“Š Airflow-Cosmos + dbt + ClickHouse

A complete **end-to-end analytics platform** that integrates:

- **ClickHouse** â†’ Fast OLAP database
- **dbt** â†’ Transformations (bronze â†’ silver â†’ gold layers)
- **Airflow + Cosmos** â†’ Orchestration
- **Astro (Docker)** â†’ Local Airflow runtime

This project demonstrates a **Food Truck Analytics** pipeline: from raw orders, menus, trucks, and sessions â†’ to cleaned marts with daily sales, funnels, and top locations.

---

## âœ¨ Features

- âœ… Ready-to-use **local stack** with Astro CLI
- âœ… **Cosmos integration** to run dbt commands inside Airflow DAGs
- âœ… **ClickHouse adapter for dbt** preconfigured
- âœ… **Food Truck demo models** with seeds, tests, and marts
- âœ… Modular folder structure for DAGs, dbt project, and configs

---

## ğŸ—ï¸ Architecture

```
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚         Astro (Docker)            â”‚
            â”‚  Airflow: Webserver | Scheduler   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                      Cosmos Operator
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”
                     â”‚     dbt       â”‚
                     â”‚ (models/tests)â”‚
                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€---â”
                     â”‚  ClickHouse     â”‚
                     â”‚ rawâ†’bronzeâ†’gold |
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€---â”˜
```

### DAG Lineage

![Food Truck Data Pipeline](images/food_truck_data_pipeline-graph-2.png)

*Complete data lineage showing the flow from raw data through staging, intermediate, and marts layers*

---

## ğŸ“‚ Repository Layout

```
.
â”œâ”€ dags/                     # Airflow DAGs (Cosmos dbt orchestration + helpers)
â”œâ”€ analytics/                # dbt project (models, seeds, profiles)
â”œâ”€ include/                  # Assets available to Airflow at runtime
â”œâ”€ tests/                    # DAG/unit tests with pytest
â”œâ”€ Dockerfile                # Astro base image + dependencies
â”œâ”€ requirements.txt          # Python deps (dbt, cosmos, clickhouse-connect, etc.)
â”œâ”€ docker-compose.override.yml
â””â”€ README.md
```

---

## âš¡ Quickstart

### 1. Install prerequisites

- [Docker](https://docs.docker.com/get-docker/)
- [Astro CLI](https://www.astronomer.io/docs/astro/cli/install-cli)

### 2. Start Airflow (Astro)

```bash
# from repo root
astro dev start
```

UI available at ğŸ‘‰ [http://localhost:8080](http://localhost:8080)  
(Default: user `admin` / pwd `admin`)

### 3. Configure connections

In Airflow UI â†’ _Admin â†’ Connections_:

### 4. Configure dbt

Edit `analytics/profiles.yml`:

### 5. Run pipeline

- Trigger DAG: `food_truck_data_pipeline`

---

## ğŸ”§ Ingestion Pipeline Setup

- Config Driven:
  DDL statements and S3 paths in `dags/config/tables_info.py`, and set the following environment variables in your `.env` file:

```env
# âš™ï¸ ClickHouse Configuration
CLICKHOUSE_HOST=host.docker.internal
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=
CLICKHOUSE_PASSWORD=
CLICKHOUSE_DATABASE=

# â˜ï¸ AWS S3 Configuration
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1
S3_BUCKET=your-bucket
S3_PREFIX=food_truck/raw/
```

## ğŸ½ï¸ Food Truck Demo Models

### Data Pipeline Overview

**20 Models | 143 Tests | 3-Layer Medallion Architecture**

### Raw Layer (Bronze)
8 source tables loaded from S3:
- `raw_franchise` - Franchise owner information
- `raw_country` - Country and city master data
- `raw_customer_loyalty` - Customer loyalty program data
- `raw_truck` - Food truck fleet information
- `raw_location` - Operating location details
- `raw_menu` - Menu items and pricing
- `raw_order_header` - Order transaction headers
- `raw_order_detail` - Order line items

![Raw Data Layer](images/1*CgPOptqGehCjUiT1UcydXg.webp)

### Staging Layer (Silver)
8 staging models with data cleaning and standardization:
- `stg_countries` - Cleaned country/city data with region classifications
- `stg_franchises` - Validated franchise owner information
- `stg_locations` - Cleaned location data with business classifications
- `stg_menu` - Standardized menu items with dietary flags
- `stg_truck` - Cleaned truck fleet data with operational status
- `stg_customer_loyalty` - Validated customer data with age groups
- `stg_order_headers` - Cleaned order headers with meal period classification
- `stg_order_details` - Validated order line items

![Staging Layer](images/1*6SWDcO5dhoM_EnfYzyrnZw.webp)

### Intermediate Layer
3 models with business logic and enrichment:
- `int_customers_segmented` - RFM analysis and customer segmentation
- `int_menu_profitability` - Menu item profitability metrics
- `int_orders_enriched` - Order-level calculations and enrichments

### Marts Layer (Gold)
**Star Schema: 7 Dimensions + 2 Facts**

**Dimension Tables:**
- `dim_country` - Country master with ISO codes and currency
- `dim_city` - City details with population and timezone
- `dim_location` - Locations with business potential scores
- `dim_franchise` - Franchise owners with profile completeness
- `dim_truck` - Truck fleet with sustainability and operational metrics
- `dim_customer` - Customer 360 with segmentation and lifetime value
- `dim_menu_item` - Menu catalog with profitability classifications

**Fact Tables:**
- `fact_order` - Order transactions with all dimensional relationships
- `fact_order_detail` - Line-item level details with profit margins

![Marts Layer](images/1*DeAIiwRLu79CiTrWdcMtDQ.webp)

### Key Features

âœ¨ **Customer Analytics**
- RFM segmentation (VIP, Loyal, Regular, At Risk, etc.)
- Lifetime value estimation (up to $200K for VIP customers)
- Communication preference analysis

âœ¨ **Menu Optimization**
- BCG matrix classification (Stars, Cash Cows, Dogs, Question Marks)
- Profitability analysis with margin tracking
- Dietary accommodation scoring

âœ¨ **Operational Metrics**
- Truck sustainability scoring (EV flagging, vehicle age)
- Location business potential analysis
- Order channel and meal period tracking

âœ¨ **Data Quality**
- 143 comprehensive tests across all layers
- Primary key uniqueness validation
- Foreign key integrity checks
- Business rule validations

---

## ğŸ§ª Testing

### dbt Tests
**143 data quality tests** covering:
- âœ… Primary key uniqueness and NOT NULL constraints
- âœ… Foreign key NOT NULL validations
- âœ… Categorical value validations (order channels, meal periods, etc.)
- âœ… Range validations for critical metrics (customer age, menu prices, LTV)
- âœ… Data quality flags (valid pricing, completeness checks)

**Run tests via Airflow:**
- Tests execute automatically in the `dbt_test` task within the DAG

**Run tests locally:**
```bash
cd analytics
dbt test
```

### DAG Tests
```bash
pytest tests/dags/ -v
```

### ClickHouse Compatibility
âœ… All tests optimized for ClickHouse:
- Boolean values stored as UInt8 (0/1)
- Explicit NULL type casting for nullable columns
- Test strategy focused on data integrity, not business variability

---

## ğŸ”§ Development workflow

```bash
# stop services
astro dev stop

# rebuild with deps
astro dev restart --rebuild

# view logs
astro dev logs -f
```

---

## ğŸš€ Roadmap

- [ ] Add Kafka â†’ ClickHouse streaming ingest example
- [ ] CI pipeline with `dbt build --warn-error`
- [ ] Preconfigured dashboards - `superset`

---

## ğŸ“œ License

MIT (or update to your orgâ€™s preference)

---

## ğŸ™Œ Credits

Built with â¤ï¸ by [SaiPurushoth](https://github.com/SaiPurushoth)  
Powered by **Astro**, **Airflow**, **dbt**, **Cosmos**, and **ClickHouse**
